{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f5fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "spacyModel = spacy.load('en_core_web_sm')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc1a579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1799                                           So far we have enjoyed it.  The only problem we have is I have not been able to call one of my sons with it (the sad part is he is the one who gave it to me:( )\n",
       "2091    This is a great tool (toy?), room-filling music, very convenient to use, just fun to have. Why only 4 stars? Supposed to work with Logitech Harmony remote: nope. Supposed to work with Denon AV rec...\n",
       "3021                                           LOVE it. I got this for my boyfriend for his birthday and his kids have a blast asking Alexa all kinds of questions and having her tell silly jokes. We love it.\n",
       "114                                                       Still learning all the ways to use it.  It is a real hit with my grandkids who ask it to play music and then dance to it.  (5 and 7 yrs).  Very cute.\n",
       "56                                                                                                                                    Works as advertised. Very easy to setup. Still learning what this can do.\n",
       "Name: verified_reviews, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.read_csv('amazon_alexa.tsv', sep='\\t')['verified_reviews']\n",
    "sentences.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d8c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in spacyModel(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "    if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf51ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3150/3150 [00:21<00:00, 144.27it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_pairs = []\n",
    "\n",
    "for i in tqdm(sentences):\n",
    "  entity_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c20375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "  doc = spacyModel(sent)\n",
    "\n",
    "  # Matcher class object \n",
    "  matcher = Matcher(spacyModel.vocab)\n",
    "\n",
    "  #define the pattern \n",
    "  pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"matching_1\", [pattern]) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cce7778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/3150 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E178] Each pattern should be a list of dicts, but got: {'DEP': 'ROOT'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('matching_1', [pattern])`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m relations \u001b[38;5;241m=\u001b[39m [get_relation(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(sentences)]\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m relations \u001b[38;5;241m=\u001b[39m [\u001b[43mget_relation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(sentences)]\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mget_relation\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#define the pattern \u001b[39;00m\n\u001b[1;32m      9\u001b[0m pattern \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROOT\u001b[39m\u001b[38;5;124m'\u001b[39m}, \n\u001b[1;32m     10\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprep\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     11\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m},  \n\u001b[1;32m     12\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOS\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADJ\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m}] \n\u001b[0;32m---> 14\u001b[0m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatching_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     16\u001b[0m matches \u001b[38;5;241m=\u001b[39m matcher(doc)\n\u001b[1;32m     17\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(matches) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/spacy/matcher/matcher.pyx:118\u001b[0m, in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E178] Each pattern should be a list of dicts, but got: {'DEP': 'ROOT'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('matching_1', [pattern])`"
     ]
    }
   ],
   "source": [
    "relations = [get_relation(i) for i in tqdm(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subject\n",
    "source = [i[0] for i in entity_pairs]\n",
    "\n",
    "# extract object\n",
    "target = [i[1] for i in entity_pairs]\n",
    "\n",
    "kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3cbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed-graph from a dataframe\n",
    "G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n",
    "                          edge_attr=True, create_using=nx.MultiDiGraph())\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159babb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
